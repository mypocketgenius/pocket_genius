# Scrum Chatbots Implementation Plan

## Executive Summary

This plan outlines building 5 specialized AI chatbots targeting validated Scrum ceremony problems. Each bot leverages the existing Pocket Genius RAG architecture to deliver superior outcomes compared to free ChatGPT through structured inputs, persistent context, authoritative citations, and feedback-driven improvement.

Why these 5 problems? See Planning Docs/02-02_validating_scrum_problems.md

---

## Part 1: The Five Tools to Build

### Tool 1: Story Crafter (User Story Generator)

**Problem solved:** Vague user stories create refinement churn. 52% of stories lack value statements, acceptance criteria merely restate narratives, and teams spend excessive time seeking clarification.

**What it does:** Generates INVEST-compliant user stories with proper personas, value statements, and acceptance criteria based on user's product context and feature description.

**Primary output:** Complete user story with:
- Role-based persona (not generic "As a user")
- Clear need statement
- Explicit value/benefit ("so that...")
- 3-5 acceptance criteria in Given-When-Then format
- Story point complexity indicator
- Potential edge cases to consider

---
✨ Generated by Story Crafter | Try it free at mypocketgenius.com/story-crafter

---

### Tool 2: Goal Architect (Sprint Goal Generator)

**Problem solved:** Sprint Goal wordsmithing consumes excessive time. Teams default to "complete everything" non-goals or spend 30+ minutes debating phrasing.

**What it does:** Generates 3-5 Sprint Goal options using proven templates, connected to the user's Product Goal and current sprint scope.

**Primary output:**
- 3-5 alternative Sprint Goal formulations
- Each following Pichler's template: "We focus on [objective] to [benefit] confirmed by [metric]"
- Outcome-focused (not task-focused)
- Measurable success indicators

---
✨ Generated by Goal Architect | Try it free at mypocketgenius.com/goal-architect

---

### Tool 3: Standup Coach (Daily Scrum Talking Points)

**Problem solved:** Daily Scrums devolve into status reports. 64% of teams experience command-control tensions, and senior developers are most negative about these meetings.

**What it does:** Transforms raw updates into Sprint Goal-focused talking points that facilitate genuine collaboration rather than status reporting.

**Primary output:**
- 2-3 Sprint Goal-aligned talking points
- Highlighted blockers with suggested discussion framing
- Collaboration opportunities with specific team members
- "Are we on track?" assessment

---
✨ Generated by Standup Coach | Try it free at mypocketgenius.com/standup-coach

---

### Tool 4: Retro Catalyst (Retrospective Question Generator)

**Problem solved:** Retrospective fatigue produces declining engagement. <50% of action items get completed, teams revisit identical problems sprint after sprint.

**What it does:** Generates fresh retrospective questions tailored to team's recent context, avoiding formats used recently, with built-in action item framing.

**Primary output:**
- 5-7 questions across Start/Stop/Continue or custom framework
- Novel format suggestions the team hasn't tried recently
- Action item templates tied to each question category
- One "pattern interrupt" question to surface deeper issues

---
✨ Generated by Retro Catalyst | Try it free at mypocketgenius.com/retro-catalyst

---

### Tool 5: Stakeholder Translator (Sprint Communication Generator)

**Problem solved:** Sprint Reviews lack focus, stakeholder no-show rates hit 50%, and POs spend excessive time writing release notes.

**What it does:** Translates technical accomplishments into business-focused summaries tailored to stakeholder audience.

**Primary output:**
- Executive summary (2-3 sentences)
- Business value delivered (quantified where possible)
- Customer impact statement
- Upcoming priorities teaser
- Suggested talking points for Sprint Review demo

---
✨ Generated by Stakeholder Translator | Try it free at mypocketgenius.com/stakeholder-translator

---

## Part 2: Existing Platform Architecture

### Current Tech Stack (Fully Reusable)

| Layer | Technology | Relevance to New Tools |
|-------|------------|------------------------|
| **Frontend** | Next.js 15, React 18, TypeScript | Chat UI, intake forms, pills already built |
| **Backend** | Next.js API Routes, Vercel Serverless | Chat endpoint, streaming infrastructure ready |
| **Database** | PostgreSQL (Neon), Prisma ORM | User, Conversation, Message, Intake schemas exist |
| **Auth** | Clerk | User identity, anonymous access supported |
| **AI/LLM** | OpenAI GPT-4o, Vercel AI SDK | Chat completions, streaming in place |
| **Embeddings** | OpenAI text-embedding-3-small | 1536-dimension vectors for RAG |
| **Vector DB** | Pinecone | Namespace per chatbot, query pipeline ready |
| **File Storage** | Vercel Blob | Content ingestion pipeline exists |
| **Analytics** | Chunk_Performance, Event, Pill_Usage tables | Feedback loops trackable |

### Key Existing Components

**Chat System (`/app/api/chat/route.ts`):**
- Streaming SSE responses
- RAG query integration
- User context injection into prompts
- Follow-up pill generation
- Message storage with source attribution

**Intake System:**
- `Intake_Question` model supports: TEXT, SELECT, MULTI_SELECT, BOOLEAN, NUMBER
- `Intake_Response` stores answers per user/chatbot
- `intake-form.tsx` renders multi-question forms
- Intake gate logic determines when to show intake vs chat

**Feedback System:**
- Helpful/not helpful per message
- Chunk performance tracking
- Pill usage analytics
- Conversation-end ratings

**Chatbot Versioning:**
- `Chatbot_Version` for immutable config snapshots
- System prompts, RAG settings, model selection

---

## Part 3: Additional Architecture Required

### 3.1 No New Database Models Required

The existing schema already supports everything needed. Each Scrum chatbot is just another chatbot on the platform.

| Need | Existing Model | How to Use |
|------|----------------|------------|
| Sprint context (product goal, sprint goal, team size) | `User_Context` | Keys: `product_goal`, `current_sprint_goal`, `team_size`, `sprint_length_days` |
| Team members | `User_Context` | Key: `team_members` with JSON array value |
| Recent retro formats used | `User_Context` | Key: `last_retro_formats` with JSON array (per-chatbot) |
| Tool-specific config | `Chatbot.configJson` | Follow-up pills, custom prompts |
| Output history | `Message` | Already stores `content` + `context` (JSON) |
| Feedback on outputs | `Chunk_Performance`, `Event`, `Conversation_Feedback` | Existing feedback system |
| Intake questions | `Intake_Question` + `Chatbot_Intake_Question` | Create questions, link to chatbot |

**Example User_Context entries for Scrum tools:**

```json
// Per-user, global (chatbotId = null) - reusable across all Scrum chatbots
{ "key": "product_goal", "value": "Enable SMBs to manage inventory without spreadsheets" }
{ "key": "team_size", "value": 6 }
{ "key": "sprint_length_days", "value": 14 }
{ "key": "team_members", "value": [{"name": "Alice", "role": "Developer"}, {"name": "Bob", "role": "QA"}] }

// Per-user, per-chatbot (Retro Catalyst only)
{ "chatbotId": "retro-catalyst-id", "key": "last_retro_formats", "value": ["sailboat", "4ls", "start_stop_continue"] }

// Per-user, per-chatbot (Standup Coach) - updated each sprint
{ "chatbotId": "standup-coach-id", "key": "current_sprint_goal", "value": "Deliver MVP checkout flow" }
```

**Example Chatbot.configJson:**

```json
{
  "enableFollowUpPills": true,
  "followUpPillsPrompt": "Generate follow-up questions about Scrum best practices"
}
```

### 3.2 No New API Endpoints Required

All 5 Scrum chatbots use the existing `/api/chat` endpoint. The differentiation comes from:

1. **Chatbot-specific system prompts** - stored in `Chatbot.systemPrompt`
2. **Chatbot-specific RAG namespace** - stored in `Chatbot.pineconeNs`
3. **Chatbot-specific intake questions** - linked via `Chatbot_Intake_Question`

The chat endpoint already:
- Fetches user context and injects into prompt
- Queries the chatbot's RAG namespace
- Streams responses
- Stores messages with context
- Generates follow-up pills

### 3.3 Structured Output via Prompt Engineering

Structured output is achieved through prompt engineering, not code. The system prompt instructs the LLM to output in a specific format (markdown with consistent headers).

**Why prompt engineering over formal schemas (`streamObject()`):**

1. **Conversational flexibility** - Users can ask follow-up questions ("What does INVEST mean?") and get natural responses, not forced into a schema
2. **Simplicity** - No schema definitions, no mode switching, no parsing logic
3. **Good enough** - 90-95% format consistency is acceptable; users can ask for regeneration if needed
4. **Works for all chatbot types** - Same approach for Scrum tools, book Q&A, landing page writers

**Example: Story Crafter output format instruction (in system prompt):**

```
When generating a user story, format your response as follows:

## User Story
**As a** [specific persona]
**I want to** [need]
**So that** [benefit]

## Acceptance Criteria
1. **Given** [context] **When** [action] **Then** [outcome]
2. ...

## Complexity: [XS/S/M/L/XL]

## Edge Cases to Consider
- [edge case 1]
- [edge case 2]

## INVEST Compliance
- Independent: [Yes/No - explanation]
- Negotiable: [Yes/No - explanation]
...

---
✨ Generated by Story Crafter | Try it free at mypocketgenius.com/story-crafter
```

**When the user asks a question instead of requesting generation**, the LLM naturally responds conversationally without forcing the structured format. This is the key advantage over schema-enforced output.

This renders cleanly in the existing markdown renderer. No new UI components needed.

### 3.4 No New UI Components Required

The existing chat UI handles everything:
- `chat.tsx` - renders messages with markdown
- `markdown-renderer.tsx` - formats structured output
- `intake-form.tsx` - handles all intake question types
- Copy buttons already exist on messages
- Feedback (thumbs up/down) already exists

### 3.5 System Prompt Configuration

Each chatbot's behavior is defined entirely by its `systemPrompt` field in the database. No new code modules needed—just well-crafted prompts stored as text.

**Key prompt components for each tool:**
1. Role definition (who the AI is)
2. Output format specification (markdown template)
3. RAG context injection placeholder (`{rag_context}`)
4. User context injection placeholder (`{user_context}`)
5. Citation requirements
6. Guardrails (what not to do)

### 3.6 Input Strategy: Why JIRA/Git Integration Is Not Required

A common assumption is that Scrum tools need to pull data from project management systems. **This is not true for advisory/generative tools.** The 5 tools we're building generate artifacts (stories, goals, talking points)—they don't track or report on work. Here's how each tool gets the context it needs without integration complexity.

#### Why Integration-Free Works

| Integration Approach | Pros | Cons |
|---------------------|------|------|
| **JIRA/Git API integration** | Auto-populated fields, less typing | OAuth complexity, enterprise security reviews, multi-provider support (Jira, Linear, Asana, GitHub, GitLab...), ongoing API maintenance, delayed time-to-market |
| **Manual intake (our approach)** | Ships fast, works with any workflow, no security friction, user controls what's shared | User must type/paste context |

**The key insight:** Users already have the information in their heads or on their screens. A 30-second intake form is faster than a 3-week integration project—and works for users on any toolchain.

#### Tool-by-Tool Input Analysis

---

**Tool 1: Story Crafter**

| Input Needed | Source Without Integration | Why It Works |
|--------------|---------------------------|--------------|
| Product/feature area | User types (persisted in User_Context) | User knows what they're working on—they came to write a story about it |
| User persona | SELECT + optional text | Common personas are predictable; "Other" handles edge cases |
| What the user needs to do | User types 1-2 sentences | This IS the story—user must articulate the need regardless of tooling |
| Why they need it | User types | Forces user to think about value (improves story quality) |
| Known acceptance criteria | Optional text | User pastes from existing notes/tickets if available |
| Complexity estimate | SELECT (S/M/L/XL) | Rough sizing doesn't need ticket history |
| Technical constraints | Optional text | User knows their stack |

**What JIRA integration would add:** Auto-suggest related epics, link to existing tickets.
**Why we skip it:** Nice-to-have, not must-have. User can reference epics in text. Integration adds weeks of scope for marginal UX improvement.

**Friction mitigation:**
- Persist `product_goal` and `team_context` in User_Context so repeat users don't re-enter
- Pre-fill from last session where applicable

---

**Tool 2: Goal Architect**

| Input Needed | Source Without Integration | Why It Works |
|--------------|---------------------------|--------------|
| Product Goal | User types (persisted) | Strategic context—user knows this, it rarely changes |
| Sprint theme | User types 1 sentence | User is in Sprint Planning; they know the theme |
| 2-4 key planned items | User types bullet points | User has this in their head or on a planning board |
| Stakeholders | MULTI_SELECT | Predefined options cover 90% of cases |
| Target metric | Optional text | User knows if there's a specific target |
| What would make sprint a failure | Optional text | Frames goal negatively to surface risks |

**What JIRA integration would add:** Pull sprint backlog items automatically.
**Why we skip it:** User can paste 4 bullet points in 20 seconds. Integration requires: OAuth flow, Jira/Linear/Asana support, sprint detection logic, item summarization. Weeks of work for 20 seconds of user effort saved.

**Friction mitigation:**
- Product Goal persists across sprints (entered once)
- Sprint theme from previous session shown as placeholder/suggestion

---

**Tool 3: Standup Coach**

| Input Needed | Source Without Integration | Why It Works |
|--------------|---------------------------|--------------|
| Current Sprint Goal | User types (persisted for sprint duration) | Entered once per sprint, reused daily |
| What you worked on yesterday | User types 2-3 sentences | User knows this—it's the point of standup |
| Blocker status | SELECT (No/Waiting/Technical/Unclear/Other) | Structured selection is faster than parsing Git commits |
| Blocker description | Conditional text | Only shown if blocked—minimal friction |
| Today's focus | User types 1-2 sentences | User is planning their day anyway |
| Collaboration needs | Optional text | Quick mention of names |

**What Git integration would add:** Auto-generate "what I did" from commits.
**Why we skip it:**
1. Commits ≠ standup updates (commit messages are technical; standup talking points are Sprint Goal-focused)
2. Many users don't commit daily or work on non-code tasks
3. GitHub/GitLab/Bitbucket support triples integration scope
4. Privacy concerns: some users won't connect their repo

**The reframe:** Our value isn't "auto-fill what you did"—it's "transform your raw update into Sprint Goal-aligned talking points." The transformation is the product, not the data pull.

**Friction mitigation:**
- Sprint Goal persists for 2 weeks (one-time entry per sprint)
- Daily use = muscle memory; users get fast at the 60-second input
- Optional: "Same as yesterday" quick-fill for focus field

---

**Tool 4: Retro Catalyst**

| Input Needed | Source Without Integration | Why It Works |
|--------------|---------------------------|--------------|
| Sprint rating | SELECT (1-5 scale) | Quick pulse check |
| Recent retro formats | MULTI_SELECT | User remembers last 2-3 formats; we persist history |
| Theme to explore | SELECT (collaboration, technical, process, etc.) | Predefined categories cover common themes |
| Team energy/morale | SELECT (High/Medium/Low/Mixed) | Facilitator's read on the room |
| Major sprint events | Optional text | User mentions what stood out |
| Preferred duration | SELECT (30/45/60/90 min) | Simple constraint |

**What JIRA integration would add:** Pull completed vs. incomplete items, velocity trends.
**Why we skip it:** Retro questions aren't about metrics—they're about team dynamics, process, and improvement. Knowing "we completed 8 of 10 stories" doesn't generate better retro questions than knowing "the sprint felt challenging."

**Friction mitigation:**
- `last_retro_formats` auto-tracked per user—no manual entry after first use
- Format variety is the feature (remembering what you've done), not sprint metrics

---

**Tool 5: Stakeholder Translator**

| Input Needed | Source Without Integration | Why It Works |
|--------------|---------------------------|--------------|
| Primary audience | SELECT (executives, sales, customers, etc.) | User knows who they're writing for |
| What was delivered | User types/pastes bullet points | **This is the main input**—see below |
| Business value delivered | Optional text | User articulates impact |
| Metrics to highlight | Optional text | User knows key numbers |
| What's coming next | Optional text | Teaser for next sprint |
| What didn't get done | Optional text | Manages expectations |
| Preferred tone | SELECT (formal, conversational, etc.) | Quick style selection |

**What JIRA integration would add:** Auto-pull completed tickets with descriptions.
**Why we skip it:**
1. Ticket titles/descriptions are often technical jargon—need translation anyway
2. Not all "done" items are stakeholder-relevant (tech debt, bug fixes, refactors)
3. User must curate what to highlight regardless of integration
4. PO/SM already has a mental list of "what we shipped that matters"

**The reframe:** The value isn't "list what got done" (user knows this)—it's "translate technical accomplishments into business language stakeholders care about."

**Friction mitigation:**
- Intake question says "List what was delivered (paste from your sprint board if helpful)"
- User can literally paste Jira ticket titles and the AI translates them
- Persistent company context (product_goal, stakeholder preferences) improves output over time

---

#### Summary: Integration Adds Scope, Not Value

| Tool | Integration Would Save | Integration Would Cost | Decision |
|------|------------------------|------------------------|----------|
| Story Crafter | Typing product context | OAuth, multi-provider, weeks of dev | Skip—persist context instead |
| Goal Architect | Typing 4 bullet points | Sprint detection, backlog parsing | Skip—20 sec user effort |
| Standup Coach | Typing "what I did" | Git provider support, commit→update translation, privacy concerns | Skip—transformation is the value |
| Retro Catalyst | Nothing meaningful | Velocity parsing for unused data | Skip—not relevant to retro questions |
| Stakeholder Translator | Copy-pasting ticket list | Completed item detection, relevance filtering | Skip—user curates anyway |

**Bottom line:** For generative/advisory tools, the user's 30-60 seconds of input is not the bottleneck. The bottleneck is producing high-quality, contextual output. Focus engineering effort there, not on integration plumbing that delays launch by months.

#### Future Integration Opportunities (Post-Traction)

Once we have paying users and validated demand, integrations become *output destinations*, not input sources:

| Integration | Value | Priority |
|-------------|-------|----------|
| **Jira: Create story from output** | One-click to backlog | High (post-MVP) |
| **Slack: Post standup/summary** | Share without copy-paste | Medium |
| **Notion: Export to workspace** | Documentation workflow | Medium |
| **Linear: Create issue** | Alternative to Jira | Medium |
| **Calendar: Sprint dates** | Auto-detect sprint boundaries | Low |

These are simpler than input integrations (write-only, no parsing) and directly requested by users ("I love the output, can I send it to Jira?").

---

## Part 4: Marketing Positioning Strategy

### Overall Positioning

**Brand:** "Pocket Scrum Master" (or similar)
**Tagline:** "Expert Scrum guidance that remembers your context"

**Core differentiators vs ChatGPT Free:**

| Feature | ChatGPT Free | Pocket Scrum Tools |
|---------|--------------|-------------------|
| Context persistence | None (forgets each session) | Remembers product goal, team, past formats |
| Output structure | Unstructured text | Consistent, copy-ready artifacts |
| Source citations | None | Scrum Guide, authoritative trainers |
| Domain expertise | Generic | Curated Scrum best practices |
| Feedback learning | None | Improves based on what works for YOUR team |
| Intake flow | Manual prompting | Guided questions gather right context |

### Tool-Specific Positioning

#### Story Crafter
**Headline:** "User stories that don't need refinement meetings to fix"
**Pain point:** "Stop wasting sprint time clarifying vague stories"
**Proof point:** "Based on INVEST criteria from Mike Cohn and Roman Pichler's persona frameworks"
**ChatGPT comparison:** "ChatGPT gives you a story. Story Crafter gives you a story your team can actually estimate and build."

#### Goal Architect
**Headline:** "Sprint Goals in 5 minutes, not 50"
**Pain point:** "End wordsmithing debates with proven goal templates"
**Proof point:** "Uses Roman Pichler's template referenced 27 times in the Scrum Guide training"
**ChatGPT comparison:** "ChatGPT suggests goals. Goal Architect gives you 5 options in the exact format Scrum trainers recommend."

#### Standup Coach
**Headline:** "Daily Scrums that aren't status reports"
**Pain point:** "Transform monotone updates into Sprint Goal conversations"
**Proof point:** "Implements the 2020 Scrum Guide's shift away from the three questions anti-pattern"
**ChatGPT comparison:** "ChatGPT doesn't know your Sprint Goal. Standup Coach keeps every update connected to it."

#### Retro Catalyst
**Headline:** "Retrospectives your team actually wants to attend"
**Pain point:** "Break the Groundhog Day cycle of discussing the same issues"
**Proof point:** "Draws from Retromat's 100+ formats, tracks what you've used to ensure variety"
**ChatGPT comparison:** "ChatGPT suggests retro questions. Retro Catalyst remembers which formats you've tried and suggests fresh ones."

#### Stakeholder Translator
**Headline:** "Sprint updates stakeholders actually read"
**Pain point:** "Stop losing stakeholders to boring technical demos"
**Proof point:** "Follows Scrum.org's guidance on avoiding 'Sprint accounting' anti-pattern"
**ChatGPT comparison:** "ChatGPT writes summaries. Stakeholder Translator writes summaries that speak your stakeholders' language because it knows your product."

### Target Audience Segments

1. **Primary:** Scrum Masters (responsible for ceremony quality)
2. **Secondary:** Product Owners (write stories, communicate with stakeholders)
3. **Tertiary:** Developers stepping into SM/PO roles (lack formal training)
4. **Enterprise:** Agile Coaches supporting multiple teams

---

## Part 5: Content to Vectorize

### Global Knowledge Base (All Tools)

| Source | Content | Priority |
|--------|---------|----------|
| **Scrum Guide 2020** | Full text (13 pages) | Critical |
| **Scrum.org PST Articles** | Stefan Wolpers' anti-pattern series, Stephanie Ockerman's Sprint Goal guides | Critical |
| **Mountain Goat Software** | Mike Cohn's user story articles, estimation guides | Critical |
| **Roman Pichler** | Sprint Goal templates, Product Goal framework, persona guides | Critical |
| **Retromat** | All 100+ retrospective formats (descriptions, instructions) | High |
| **State of Agile Reports** | 2023-2025 data on ceremony challenges | Medium |
| **Agile Manifesto + Principles** | 4 values, 12 principles | Medium |

### Tool-Specific Knowledge

#### Story Crafter
| Source | Content |
|--------|---------|
| Mike Cohn's "User Stories Applied" excerpts | INVEST criteria, story splitting patterns |
| Roman Pichler's persona templates | User Incognito anti-pattern, effective persona structure |
| BDD resources | Given-When-Then format, acceptance criteria best practices |
| Story splitting techniques | SPIDR method, workflow steps, business rules |
| Common anti-patterns | Solution prescribing, compound stories, missing value |

#### Goal Architect
| Source | Content |
|--------|---------|
| Roman Pichler's Goal templates | Focus-benefit-metric framework |
| Sprint Goal anti-patterns | Too vague, too compound, too specific examples |
| Product Goal alignment | Connecting Sprint Goals to Product Goals |
| Goal measurement techniques | Leading vs lagging indicators for sprints |

#### Standup Coach
| Source | Content |
|--------|---------|
| Scrum Guide 2020 | Daily Scrum purpose, removal of three questions |
| "Walk the board" technique | Work-item focus vs person focus |
| Collaboration patterns | How to surface impediments productively |
| Anti-pattern library | Status reporting, problem-solving in standup, manager dynamics |

#### Retro Catalyst
| Source | Content |
|--------|---------|
| Retromat full database | 100+ formats with facilitation instructions |
| Action item best practices | SMART actions, Sprint Backlog integration |
| Psychological safety research | Creating safe retro environments |
| Facilitation techniques | Silent writing, dot voting, 1-2-4-all |
| Fatigue mitigation | Format rotation strategies, engagement techniques |

#### Stakeholder Translator
| Source | Content |
|--------|---------|
| Sprint Review anti-patterns | Sprint accounting, passive stakeholders, death by PowerPoint |
| Business communication guides | Technical-to-business translation frameworks |
| Value articulation | Outcome vs output language |
| Stakeholder engagement | Interactive demo techniques, feedback collection |

### Estimated Vector Counts

| Tool | Chunks (est.) | Reasoning |
|------|---------------|-----------|
| Global base | ~500 | Core Scrum knowledge |
| Story Crafter | +200 | Story techniques, examples |
| Goal Architect | +100 | Goal templates, anti-patterns |
| Standup Coach | +100 | Daily Scrum practices |
| Retro Catalyst | +300 | 100+ formats with instructions |
| Stakeholder Translator | +100 | Communication patterns |
| **Total** | ~1,300 | Per-tool namespace approach |

---

## Part 6: Implementation Roadmap

Since each tool is just a new Chatbot record using the existing platform, implementation is primarily content + configuration work.

### Phase 1: Content & Foundation (Weeks 1-2)

**Week 1: Content Collection**
- [ ] Collect Scrum Guide 2020 (full text)
- [ ] Collect Scrum.org PST articles (Wolpers, Ockerman)
- [ ] Collect Mike Cohn user story materials
- [ ] Collect Roman Pichler goal/persona templates
- [ ] Scrape/compile Retromat formats (100+)
- [ ] Format all content for chunking

**Week 2: Content Ingestion & Namespaces**
- [ ] Create 5 Pinecone namespaces (one per tool)
- [ ] Chunk and embed global Scrum knowledge to all namespaces
- [ ] Add tool-specific content to each namespace
- [ ] Verify RAG retrieval quality with test queries
- [ ] Document which content is in which namespace

### Phase 2: Tool 1 - Story Crafter (Week 3)

- [ ] Create Chatbot record with system prompt for user story generation
- [ ] Configure `configJson` with structured output schema
- [ ] Create intake questions (8 questions per Part 10)
- [ ] Link intake questions via `Chatbot_Intake_Question`
- [ ] Test end-to-end: intake → chat → structured story output
- [ ] Refine system prompt based on output quality

### Phase 3: Tool 2 - Goal Architect (Week 4)

- [ ] Create Chatbot record with Sprint Goal system prompt
- [ ] Configure for multi-option output (3-5 goals)
- [ ] Create intake questions (6 questions)
- [ ] Test with various sprint themes
- [ ] Ensure Product Goal context carries through

### Phase 4: Tool 3 - Standup Coach (Week 5)

- [ ] Create Chatbot record with Daily Scrum system prompt
- [ ] Create intake questions (6 questions, daily use)
- [ ] Configure to reference Sprint Goal from User_Context
- [ ] Test talking point generation
- [ ] Optimize for speed (daily use = low latency matters)

### Phase 5: Tool 4 - Retro Catalyst (Week 6)

- [ ] Create Chatbot record with retro question system prompt
- [ ] Create intake questions (6 questions)
- [ ] Implement format tracking via User_Context (`last_retro_formats`)
- [ ] Test novelty: ensure different formats each time
- [ ] Verify Retromat content retrieval works well

### Phase 6: Tool 5 - Stakeholder Translator (Week 7)

- [ ] Create Chatbot record with stakeholder communication prompt
- [ ] Create intake questions (7 questions)
- [ ] Configure audience-aware output formatting
- [ ] Test technical → business translation quality

### Phase 7: Cross-Tool Polish (Week 8)

- [ ] Ensure User_Context keys are consistent across tools
- [ ] Test that global context (product_goal, team_size) flows to all tools
- [ ] Verify feedback collection works for all tools
- [ ] Write tool descriptions and short bios
- [ ] Create welcome messages and fallback suggestion pills

### Phase 8: Launch Preparation (Weeks 9-10)

- [ ] Landing pages per tool
- [ ] Onboarding flows
- [ ] Beta user recruitment (20 users)
- [ ] Beta testing and feedback collection
- [ ] Final prompt refinements

### Phase 8: Launch Preparation (Weeks 15-16)

- [ ] Landing pages per tool
- [ ] Onboarding flows
- [ ] Analytics dashboards
- [ ] Feedback collection infrastructure
- [ ] Beta user recruitment

---

## Part 7: Feedback Loop Design

### 7.1 Implicit Feedback Signals

| Signal | What It Indicates | Collection Point |
|--------|-------------------|------------------|
| **Copy action** | Output was useful enough to use | Copy button click |
| **Edit before use** | Output needed refinement | Diff between generated and used text |
| **Session abandonment** | Output not helpful | No copy/use within 60s of generation |
| **Regeneration** | First output unsatisfactory | "Try again" button click |
| **Time to copy** | Confidence in output | Timestamp delta |
| **Full vs partial copy** | Which parts were valuable | Selection tracking |

### 7.2 Explicit Feedback Collection

**Per-Output Quick Rating:**
- Thumbs up/down on each generated artifact
- Optional: "What would make this better?" text field (shown on thumbs down)

**Weekly Digest (for active users):**
- "How many of last week's generated stories made it to sprint unchanged?" (0-100% slider)
- "Did your Sprint Goal stay relevant all sprint?" (Yes/Somewhat/No)
- "Did your retro generate actionable items?" (Yes/No)

**Outcome Tracking (opt-in):**
- "Mark this story as completed" → tracks story success
- "Mark Sprint Goal as achieved" → tracks goal quality
- "Mark action item as completed" → tracks retro effectiveness

### 7.3 Feedback Data Model

```prisma
model Tool_Feedback {
  id              String   @id @default(cuid())
  toolHistoryId   String
  toolHistory     User_Tool_History @relation(fields: [toolHistoryId], references: [id])
  feedbackType    String   // "rating", "outcome", "edit_distance", "copy_partial"
  feedbackValue   Json     // Flexible: {rating: 5}, {outcome: "achieved"}, {editDistance: 0.3}
  createdAt       DateTime @default(now())

  @@index([toolHistoryId])
}
```

### 7.4 Feedback-Driven Improvement Loop

```
┌─────────────────────────────────────────────────────────────────┐
│                        FEEDBACK LOOP                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  User Input ──► RAG Query ──► LLM Generation ──► Structured    │
│      │              │              │              Output        │
│      │              │              │                 │          │
│      │              │              │                 ▼          │
│      │              │              │         User Feedback      │
│      │              │              │         (explicit/implicit)│
│      │              │              │                 │          │
│      │              │              │                 ▼          │
│      │              │              │         Feedback DB        │
│      │              │              │                 │          │
│      ▼              ▼              ▼                 ▼          │
│  Context        Chunk          Prompt          Model Fine-     │
│  Refinement     Ranking        Tuning          tuning (future) │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Short-term improvements (automated):**
- Chunks with low satisfaction → deprioritized in retrieval
- Prompt variations A/B tested based on output ratings
- User context enriched based on common edits

**Medium-term improvements (manual review):**
- Weekly review of low-rated outputs → prompt refinement
- Monthly review of edit patterns → output format adjustments
- Quarterly content review → knowledge base updates

**Long-term improvements (model-level):**
- Fine-tuning dataset from high-rated outputs (future)
- Custom model for each tool type (future)

---

## Part 8: Monetization Model

### Pricing Philosophy

**Free tier establishes habit, paid tier captures value when stakes are high.**

Users generating a few stories or goals occasionally → free
Users relying on tools daily for professional work → paid

### Message-Based Pricing Structure

| Tier | Monthly Price | Messages/Month | Per-Message Overage |
|------|---------------|----------------|---------------------|
| **Free** | $0 | 20 | N/A (hard cap) |
| **Pro** | $19/mo | 200 | $0.15/message |
| **Team** | $49/mo | 750 | $0.10/message |
| **Enterprise** | Custom | Unlimited | N/A |

### Message Counting Logic

**What counts as 1 message:**
- Each tool generation (regardless of complexity)
- Each regeneration/retry
- Follow-up refinement in same session

**What doesn't count:**
- Viewing past outputs
- Editing outputs (client-side)
- Copying outputs
- Providing feedback

### Tool-Specific Value Capture

| Tool | Free Tier Limit | Reasoning |
|------|-----------------|-----------|
| Story Crafter | 10 stories/mo | ~2 sprints of light usage |
| Goal Architect | 4 goals/mo | 2 sprints with retries |
| Standup Coach | Unlimited | Daily habit builder, upsell driver |
| Retro Catalyst | 4 retros/mo | 2 sprints with retries |
| Stakeholder Translator | 4 summaries/mo | 2 sprints with retries |

**Strategy:** Standup Coach is unlimited on free tier to establish daily habit. Once users depend on it, the value of full suite becomes clear.

### Revenue Projections (Conservative)

| Month | Free Users | Pro Users | Team Accounts | MRR |
|-------|------------|-----------|---------------|-----|
| M3 | 500 | 25 | 2 | $573 |
| M6 | 2,000 | 100 | 10 | $2,390 |
| M12 | 8,000 | 400 | 50 | $10,050 |

**Assumptions:**
- 5% free→Pro conversion
- 0.5% free→Team conversion
- 10% monthly churn on paid

### Alternative Monetization Considered

| Model | Pros | Cons | Decision |
|-------|------|------|----------|
| Per-tool pricing | Clear value per tool | Fragments experience | Rejected |
| Seat-based | Predictable | Penalizes collaboration | Rejected |
| Feature-gating | Clear upgrade path | Frustrating UX | Rejected |
| Usage-based only | Aligns cost with value | Unpredictable bills | Partially adopted |
| **Hybrid (chosen)** | Predictable + fair | Complexity | **Selected** |

---

## Part 9: Launch Strategy

### Pre-Launch (4 weeks before)

**Week -4: Build audience**
- [ ] LinkedIn posts on each Scrum problem (cite research data)
- [ ] r/scrum, r/agile posts (value-first, not promotional)
- [ ] Collect email waitlist with "which tool interests you most?" survey

**Week -3: Beta recruitment**
- [ ] Recruit 20 beta users from waitlist
- [ ] Focus on Scrum Masters at startups (fast feedback cycles)
- [ ] Set up private Slack channel for beta

**Week -2: Beta testing**
- [ ] Beta users test all 5 tools
- [ ] Daily standups on Slack to gather feedback
- [ ] Fix critical issues, refine outputs

**Week -1: Polish**
- [ ] Implement top beta feedback items
- [ ] Prepare launch assets (screenshots, demo videos)
- [ ] Write launch posts

### Launch Day

**Primary channels:**
1. **Product Hunt** - Launch all 5 tools as one product
2. **Hacker News (Show HN)** - Focus on the RAG architecture angle
3. **LinkedIn** - Personal post from founder + company page
4. **Twitter/X** - Thread on each tool's problem/solution

**Launch messaging:**
- Lead with the validated problems (cite State of Agile data)
- Position against ChatGPT clearly in comparisons
- Offer 50% off first month for launch week signups

### Post-Launch (First 30 days)

**Week 1:**
- [ ] Respond to all Product Hunt comments
- [ ] Capture "what's missing" feedback
- [ ] Fix any critical bugs same-day

**Week 2:**
- [ ] First user interviews (5 calls)
- [ ] Identify power users for case studies
- [ ] A/B test pricing page

**Week 3:**
- [ ] Publish first case study
- [ ] Guest post on Scrum-focused blog
- [ ] Webinar: "Fixing the 5 Most Common Scrum Ceremony Problems"

**Week 4:**
- [ ] Analyze first month data
- [ ] Plan V2 features based on feedback
- [ ] Begin SEO content strategy

### Growth Channels (Ongoing)

| Channel | Strategy | Expected CAC |
|---------|----------|--------------|
| **SEO** | Long-tail: "how to write sprint goal", "retrospective questions" | $5-10 |
| **LinkedIn Organic** | Weekly problem/solution posts | $0 |
| **Partnerships** | Scrum training providers, Jira consultants | Revenue share |
| **Referral** | "Give 20 free messages, get 20" | $3-5 |
| **Paid (future)** | LinkedIn ads to Scrum Master title | $30-50 |

---

## Part 10: Structured Input Questions

### Story Crafter Intake

| # | Question | Format | Required | Options/Validation |
|---|----------|--------|----------|-------------------|
| 1 | What product or feature area is this story for? | TEXT | Yes | Max 200 chars |
| 2 | Who is the primary user of this feature? | SELECT | Yes | "End customer", "Admin user", "Internal team member", "API consumer", "Other (specify)" |
| 3 | If "Other", describe the user: | TEXT | Conditional | Shown if #2 = "Other" |
| 4 | What does this user need to do? | TEXT | Yes | Max 500 chars, placeholder: "e.g., filter search results by date range" |
| 5 | Why do they need this? What problem does it solve? | TEXT | Yes | Max 500 chars |
| 6 | Are there specific acceptance criteria you already know? | TEXT | No | Max 1000 chars |
| 7 | What's the rough complexity? | SELECT | No | "Small (< 1 day)", "Medium (1-3 days)", "Large (3-5 days)", "Epic (needs splitting)", "Not sure" |
| 8 | Any technical constraints or dependencies? | TEXT | No | Max 500 chars |

### Goal Architect Intake

| # | Question | Format | Required | Options/Validation |
|---|----------|--------|----------|-------------------|
| 1 | What is your Product Goal? (the larger objective you're working toward) | TEXT | Yes | Max 500 chars |
| 2 | What is the main theme of this sprint? | TEXT | Yes | Max 300 chars |
| 3 | List 2-4 key items planned for this sprint: | TEXT | Yes | Max 500 chars |
| 4 | Who are the primary stakeholders expecting value from this sprint? | MULTI_SELECT | No | "Customers", "Sales team", "Leadership", "Operations", "Engineering (internal tooling)", "Other" |
| 5 | Is there a specific metric or outcome you're targeting? | TEXT | No | Max 200 chars |
| 6 | What would make this sprint a failure? | TEXT | No | Max 300 chars |

### Standup Coach Intake

| # | Question | Format | Required | Options/Validation |
|---|----------|--------|----------|-------------------|
| 1 | What is your current Sprint Goal? | TEXT | Yes | Max 300 chars (persisted) |
| 2 | What did you work on since yesterday? | TEXT | Yes | Max 500 chars |
| 3 | Are you blocked on anything? | SELECT | Yes | "No blockers", "Waiting on someone", "Technical issue", "Unclear requirements", "Other" |
| 4 | If blocked, describe briefly: | TEXT | Conditional | Max 300 chars |
| 5 | What will you focus on today? | TEXT | Yes | Max 300 chars |
| 6 | Do you need to collaborate with anyone specific today? | TEXT | No | Max 200 chars |

### Retro Catalyst Intake

| # | Question | Format | Required | Options/Validation |
|---|----------|--------|----------|-------------------|
| 1 | How would you rate the last sprint overall? | SELECT | Yes | "Great (4-5)", "Good (3)", "Challenging (2)", "Difficult (1)" |
| 2 | What retro formats have you used recently? | MULTI_SELECT | No | "Start/Stop/Continue", "4 L's", "Mad/Sad/Glad", "Sailboat", "Starfish", "Timeline", "None/New team" |
| 3 | Is there a specific theme you want to explore? | SELECT | No | "Team collaboration", "Technical practices", "Process efficiency", "Communication", "Planning accuracy", "No specific theme" |
| 4 | How is team energy/morale? | SELECT | No | "High", "Medium", "Low", "Mixed" |
| 5 | Any major events this sprint worth reflecting on? | TEXT | No | Max 300 chars |
| 6 | Preferred retro duration? | SELECT | No | "30 min (quick)", "45 min (standard)", "60 min (deep dive)", "90 min (extended)" |

### Stakeholder Translator Intake

| # | Question | Format | Required | Options/Validation |
|---|----------|--------|----------|-------------------|
| 1 | Who is the primary audience for this summary? | SELECT | Yes | "Executive leadership", "Sales/customer success", "Customers directly", "Cross-functional partners", "Board/investors", "Mixed audience" |
| 2 | List what was delivered/completed this sprint: | TEXT | Yes | Max 1000 chars |
| 3 | What business value was delivered? | TEXT | No | Max 500 chars |
| 4 | Any metrics to highlight? (performance, adoption, etc.) | TEXT | No | Max 300 chars |
| 5 | What's coming next sprint that stakeholders should know? | TEXT | No | Max 300 chars |
| 6 | Anything that didn't get done that was expected? | TEXT | No | Max 300 chars |
| 7 | Preferred tone? | SELECT | No | "Formal/professional", "Conversational", "Technical (some audience)", "Celebratory" |

---

## Part 11: Additional Considerations

### 11.1 Privacy & Data Handling

**Principle:** User inputs may contain sensitive business information.

| Data Type | Retention | Sharing |
|-----------|-----------|---------|
| Intake responses | Indefinite (user value) | Never shared between users |
| Generated outputs | 90 days | Never |
| Feedback ratings | Indefinite | Aggregated only |
| Sprint context | Until user deletes | Never |

**Compliance considerations:**
- GDPR: Data export and deletion on request
- SOC 2: Consider for enterprise tier
- No PII in RAG knowledge base

### 11.2 Offline/Degraded Mode

**When OpenAI is unavailable:**
- Show cached recent outputs for reference
- Allow offline editing of past outputs
- Queue requests for retry
- Display clear "AI unavailable" status

### 11.3 Integration Opportunities (Future)

| Integration | Value | Complexity |
|-------------|-------|------------|
| Jira | Auto-create stories from output | Medium |
| Slack | Post standups, summaries | Low |
| Notion | Export stories/goals to workspace | Low |
| Calendar | Sprint timeline context | Medium |
| Linear | Issue creation | Medium |

### 11.4 Competitive Moat

**Short-term moat (0-6 months):**
- Structured outputs ChatGPT can't match
- Scrum-specific knowledge curation
- Intake flows that gather right context

**Medium-term moat (6-18 months):**
- User context that compounds value over time
- Feedback-refined outputs for each user's style
- Format history (retros) preventing repetition

**Long-term moat (18+ months):**
- Fine-tuned models on successful outputs
- Network effects from team features
- Integration ecosystem

### 11.5 Risk Mitigation

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| ChatGPT adds memory/structure | High | High | Move fast, build feedback loop moat |
| Low adoption | Medium | High | Strong free tier, daily use tool (Standup) |
| OpenAI pricing increases | Medium | Medium | Abstract provider, test Anthropic/others |
| User churn | Medium | Medium | Focus on daily habit (Standup Coach) |
| Content accuracy complaints | Low | Medium | Citations, human review process |

### 11.6 Success Metrics

**Product metrics:**
- Daily Active Users (DAU) per tool
- Messages generated per user per week
- Free→Paid conversion rate
- Net Promoter Score (NPS)
- Tool-specific satisfaction ratings

**Business metrics:**
- Monthly Recurring Revenue (MRR)
- Customer Acquisition Cost (CAC)
- Lifetime Value (LTV)
- Churn rate (monthly)
- Revenue per user

**Quality metrics:**
- Output acceptance rate (used without major edits)
- Regeneration rate (lower is better)
- Feedback rating distribution
- Time to value (first useful output)

### 11.7 Team Requirements

**To execute this plan:**
- 1 Full-stack developer (existing team can handle)
- 1 Part-time content curator (for knowledge base maintenance)
- Founder involvement for product decisions, marketing

**Future hires (post-traction):**
- Growth marketer (Month 6+)
- Customer success (Month 9+)

---

## Appendix A: System Prompt Templates

### Story Crafter System Prompt (Draft)

```
You are Story Crafter, an expert at writing INVEST-compliant user stories for Scrum teams.

## Your Knowledge
You have access to best practices from Mike Cohn, Roman Pichler, and the Scrum Guide. Use the retrieved context to ground your recommendations in established practices.

## User Context
- Product/Feature: {product_context}
- User Persona: {persona}
- Team's Definition of Ready: {dor_if_provided}

## Your Task
When asked to generate a user story, create a complete story with all required elements. When asked questions about user stories or Scrum practices, respond conversationally.

## Output Format (for story generation)
Format your response as follows:

## User Story
**As a** [specific persona]
**I want to** [need]
**So that** [benefit]

## Acceptance Criteria
1. **Given** [context] **When** [action] **Then** [outcome]
2. ...

## Complexity: [XS/S/M/L/XL]

## Edge Cases to Consider
- [edge case 1]
- [edge case 2]

## INVEST Compliance
- Independent: [Yes/No - explanation]
- Negotiable: [Yes/No - explanation]
- Valuable: [Yes/No - explanation]
- Estimable: [Yes/No - explanation]
- Small: [Yes/No - explanation]
- Testable: [Yes/No - explanation]

---
✨ Generated by Story Crafter | Try it free at mypocketgenius.com/story-crafter

## Guidelines
- Make the persona specific and relatable
- The value statement should answer "why does this matter?"
- Acceptance criteria should be testable
- Flag any INVEST violations with suggestions to fix
- If the request is too large for one story, suggest how to split it

## Retrieved Best Practices
{rag_context}
```

### Goal Architect System Prompt (Draft)

```
You are Goal Architect, an expert at crafting Sprint Goals that align teams and enable flexibility.

## Your Knowledge
You have access to Roman Pichler's Sprint Goal template, the Scrum Guide 2020, and documented anti-patterns from Scrum.org trainers.

## User Context
- Product Goal: {product_goal}
- Sprint Theme: {sprint_theme}
- Planned Items: {planned_items}
- Stakeholders: {stakeholders}

## Your Task
When asked to generate sprint goals, provide 3-5 options. When asked questions about sprint goals or Scrum practices, respond conversationally.

## Output Format (for goal generation)
Format your response as follows:

## Sprint Goal Options

### Option 1: [Short title]
**Goal:** "We focus on [objective] to [benefit/impact] confirmed by [metric/evidence]"
**Angle:** [User Value / Business Value / Learning / Risk Reduction]

### Option 2: [Short title]
...

### Recommended: Option [X]
**Why:** [Reasoning for recommendation]

### Warnings (if any)
- [Warning about scope or focus issues]

---
✨ Generated by Goal Architect | Try it free at mypocketgenius.com/goal-architect

## Guidelines
- Goals should be outcome-focused, not task lists
- Each option should emphasize a different angle (user value, business value, learning, risk reduction)
- Avoid compound goals (X AND Y AND Z)
- Include a recommended option with reasoning
- Flag if the sprint scope seems too unfocused for a single goal

## Anti-Patterns to Avoid
- "Complete all sprint backlog items" (not a goal)
- Too vague: "Improve the user experience" (how will you know?)
- Too specific: "Implement ticket #1234" (that's a task)

## Retrieved Best Practices
{rag_context}
```

---

## Appendix B: Pinecone Namespace Strategy

**Option A: Shared namespace, metadata filtering**
- All tools share one namespace
- Filter by `toolType` metadata
- Pros: Simpler management
- Cons: Larger index, potential retrieval noise

**Option B: Separate namespaces per tool (Recommended)**
- `scrum-global` - Shared Scrum knowledge
- `scrum-story-crafter` - Story-specific content
- `scrum-goal-architect` - Goal-specific content
- `scrum-standup-coach` - Daily Scrum content
- `scrum-retro-catalyst` - Retrospective formats
- `scrum-stakeholder-translator` - Communication patterns

**Query strategy:**
1. Query tool-specific namespace (top 3)
2. Query global namespace (top 2)
3. Merge and dedupe by similarity
4. Return top 5 total

---

*Document version: 1.1*
*Created: 2026-02-02*
*Updated: 2026-02-04*
*Author: Implementation Planning Session*

**Changelog:**
- v1.1 (2026-02-04): Confirmed prompt engineering approach for structured output (no Zod schemas). Added watermarks to tool outputs. Simplified system prompts with format instructions.
